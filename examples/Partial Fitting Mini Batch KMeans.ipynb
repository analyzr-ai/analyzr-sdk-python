{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Copyright (c) 2022 Go2Market Insights d/b/a Analyzr\n",
    "# All rights reserved\n",
    "# https://analyzr.ai\n",
    "# \n",
    "# The above copyright notice and this permission notice shall be included in all copies or substantial portions\n",
    "# of the Software.\n",
    "# \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO\n",
    "# THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n",
    "# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "# \n",
    "# For Python SDK reference go to https://https://analyzr-sdk-python.readthedocs.io/\n",
    "# For support go to https://support.analyzr.ai\n",
    "# \n",
    "import pandas as pd \n",
    "import datetime\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'api': {'status': 200, 'version': 'v1.7.76', 'tenant': 'Analyzr3'},\n",
       " 'client': {'version': '1.2.61'},\n",
       " 'copyright': '2023 (c) Go2Market Insights Inc. All rights reserved. Patent pending. '}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "# START ANALYZR CLIENT\n",
    "# \n",
    "# Access to the Analyzr API requires credentials. Contact your account manager or contact \n",
    "# our support team at https://support.analyzr.ai for more info. If you are a free tier user \n",
    "# you can skip this step altogether and use your local compute resources. \n",
    "# \n",
    "# For installation instructions on the Analyzr client see https://github.com/analyzr-ai/analyzr-sdk-python\n",
    "# \n",
    "from analyzrclient import Analyzer\n",
    "analyzer = Analyzer(host='analyzr3.api.g2m.ai')\n",
    "analyzer.login()\n",
    "analyzer.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# LOAD DATA\n",
    "# \n",
    "data = pd.read_csv('https://g2mstaticfiles.blob.core.windows.net/$web/titanic.csv', encoding = \"ISO-8859-1\", low_memory=False, chunksize=200)\n",
    "raw_data = pd.read_csv('https://g2mstaticfiles.blob.core.windows.net/$web/titanic.csv', encoding = \"ISO-8859-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked PassengerId\n",
       "0         0       3    male  22.0      1      0   7.2500        S           1\n",
       "1         1       1  female  38.0      1      0  71.2833        C           2\n",
       "2         1       3  female  26.0      0      0   7.9250        S           3\n",
       "3         1       1  female  35.0      1      0  53.1000        S           4\n",
       "4         0       3    male  35.0      0      0   8.0500        S           5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "# TAKE A SUBSET OF THE ORIGINAL DATASET\n",
    "# \n",
    "# This step selects a subset of the original dataset for training purposes. \n",
    "# It also assigns a record identifier field (ID_FIELD) for audit and reconciliation \n",
    "# purposes. \n",
    "# \n",
    "SELECTED_FIELDS = [\n",
    "    'Survived',\n",
    "    'Pclass',\n",
    "    'Sex',\n",
    "    'Age',\n",
    "    'SibSp',\n",
    "    'Parch',\n",
    "    'Fare',\n",
    "    'Embarked',\n",
    "    'PassengerId',\n",
    "]\n",
    "ID_FIELD = 'PassengerId'\n",
    "df = raw_data[SELECTED_FIELDS].dropna()\n",
    "df[ID_FIELD] = df[ID_FIELD].astype('string')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# ASSIGN VARIABLE TYPES\n",
    "# \n",
    "# This step assigns variable types: categorical or numerical. \n",
    "# \n",
    "CATEGORICAL_VARS = ['Sex', 'Embarked'] \n",
    "NUMERICAL_VARS = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_common(data=None, idx_field=None, categorical_fields=[], time_field=None, saturation_fields=[], carryover_fields=[], scale=False, sort_records=False):\n",
    "    \"\"\"\n",
    "    :param data:\n",
    "    :param idx_field:\n",
    "    :param categorical_fields:\n",
    "    :param time_field:\n",
    "    :param saturation_fields:\n",
    "    :param carryover_fields:\n",
    "    :param scale:\n",
    "    :param sort_records:\n",
    "    :return df:\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    dataset = pd.DataFrame(data)\n",
    "    details = []\n",
    "    # Check for NaN\n",
    "    # dataset = dataset.replace('', None)\n",
    "    nans = dataset[dataset.isnull().any(axis=1)]\n",
    "    if len(nans)>0:\n",
    "        dataset = dataset.dropna()\n",
    "\n",
    "    # Force type to float for non-categorical fields\n",
    "    for col in dataset.columns:\n",
    "        if col not in [idx_field, *categorical_fields]:\n",
    "            # dataset[col] = dataset[col].astype('float')\n",
    "            dataset[col] = pd.to_numeric(dataset[col], errors='coerce')\n",
    "\n",
    "    # Check for NaN again\n",
    "    nans = dataset[dataset.isnull().any(axis=1)]\n",
    "    if len(nans)>0:\n",
    "        dataset = dataset.dropna()\n",
    "\n",
    "    # Scale non-categorical fields if requested\n",
    "    if scale is True and dataset.empty is False:\n",
    "        noncat_cols = [col for col in dataset.columns if col not in [idx_field, *categorical_fields]]\n",
    "        dataset[noncat_cols] = StandardScaler().fit_transform(dataset[noncat_cols])\n",
    "\n",
    "    # Generate dummy variables for categorical fields\n",
    "    if dataset is not None and dataset.empty is False:\n",
    "        df = pd.get_dummies(dataset, columns=categorical_fields)\n",
    "    else:\n",
    "        msg = 'Cannot convert empty dataset'\n",
    "        details.append(msg)\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "    # Process time field\n",
    "    if sort_records is True:\n",
    "        if time_field is not None:\n",
    "            df.sort_values([time_field], inplace=True, ascending=True)\n",
    "        elif idx_field is not None:\n",
    "            df.sort_values([idx_field], inplace=True, ascending=True)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # Process saturation fields\n",
    "    pass \n",
    "\n",
    "    # Process carryover fields\n",
    "    pass\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request ID: ebde551d-b2be-43d0-bd55-38aa38dafeff\n",
      "Encoding categorical variables:\n",
      "\tSex\n",
      "\tEmbarked\n",
      "Encoding numerical variables:\n",
      "\tPclass\n",
      "\tAge\n",
      "\tSibSp\n",
      "\tParch\n",
      "\tFare\n",
      "Encoding record IDs...\n",
      "Encoding field names...\n",
      "Saving encoding keys locally...\n",
      "Saving data to buffer...\n",
      "        Processed batch 2 of 2\n",
      "Clustering data in buffer...\n",
      "[_poll][0] {'status': 200, 'response': {'request_id': 'ebde551d-b2be-43d0-bd55-38aa38dafeff', 'status': 'Complete', 'details': 'N/A'}}\n",
      "Decoding field names...\n",
      "Decoding categorical variables:\n",
      "Decoding numerical variables:\n",
      "Decoding record IDs...\n",
      "Clearing buffer...\n",
      "Request ID: b65b12fb-c3db-461b-a33b-4c634b7ab22f\n",
      "Encoding categorical variables:\n",
      "\tSex\n",
      "\tEmbarked\n",
      "Encoding numerical variables:\n",
      "\tPclass\n",
      "\tAge\n",
      "\tSibSp\n",
      "\tParch\n",
      "\tFare\n",
      "Encoding record IDs...\n",
      "Encoding field names...\n",
      "Saving encoding keys locally...\n",
      "Saving data to buffer...\n",
      "        Processed batch 4 of 4\n",
      "Clustering data in buffer...\n",
      "[_poll][0] {'status': 200, 'response': {'request_id': 'b65b12fb-c3db-461b-a33b-4c634b7ab22f', 'status': 'Complete', 'details': 'N/A'}}\n",
      "Decoding field names...\n",
      "Decoding categorical variables:\n",
      "Decoding numerical variables:\n",
      "Decoding record IDs...\n",
      "Clearing buffer...\n",
      "Request ID: 94e2522e-3b4f-4a87-894d-736b207ab218\n",
      "Encoding categorical variables:\n",
      "\tSex\n",
      "\tEmbarked\n",
      "Encoding numerical variables:\n",
      "\tPclass\n",
      "\tAge\n",
      "\tSibSp\n",
      "\tParch\n",
      "\tFare\n",
      "Encoding record IDs...\n",
      "Encoding field names...\n",
      "Saving encoding keys locally...\n",
      "Saving data to buffer...\n",
      "        Processed batch 4 of 4\n",
      "Clustering data in buffer...\n",
      "[_poll][0] {'status': 200, 'response': {'request_id': '94e2522e-3b4f-4a87-894d-736b207ab218', 'status': 'Complete', 'details': 'N/A'}}\n",
      "Decoding field names...\n",
      "Decoding categorical variables:\n",
      "Decoding numerical variables:\n",
      "Decoding record IDs...\n",
      "Clearing buffer...\n",
      "Request ID: 2a9e7622-2271-4cc3-8816-b2bc65616184\n",
      "Encoding categorical variables:\n",
      "\tSex\n",
      "\tEmbarked\n",
      "Encoding numerical variables:\n",
      "\tPclass\n",
      "\tAge\n",
      "\tSibSp\n",
      "\tParch\n",
      "\tFare\n",
      "Encoding record IDs...\n",
      "Encoding field names...\n",
      "Saving encoding keys locally...\n",
      "Saving data to buffer...\n",
      "        Processed batch 3 of 3\n",
      "Clustering data in buffer...\n",
      "[_poll][0] {'status': 200, 'response': {'request_id': '2a9e7622-2271-4cc3-8816-b2bc65616184', 'status': 'Complete', 'details': 'N/A'}}\n",
      "Decoding field names...\n",
      "Decoding categorical variables:\n",
      "Decoding numerical variables:\n",
      "Decoding record IDs...\n",
      "Clearing buffer...\n",
      "       0\n",
      "0    1.0\n",
      "1    0.0\n",
      "2    3.0\n",
      "3    3.0\n",
      "4    1.0\n",
      "..   ...\n",
      "111  3.0\n",
      "112  2.0\n",
      "113  0.0\n",
      "114  4.0\n",
      "115  3.0\n",
      "\n",
      "[712 rows x 1 columns]\n",
      "model_id: 2a9e7622-2271-4cc3-8816-b2bc65616184\n",
      "total time: 0:00:27.900516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\13038\\Anaconda3\\envs\\analyzr3-api\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('https://g2mstaticfiles.blob.core.windows.net/$web/titanic.csv', encoding = \"ISO-8859-1\", low_memory=False, chunksize=250)\n",
    "t_0 = datetime.datetime.now()\n",
    "total_clusters = pd.DataFrame()\n",
    "scores = pd.DataFrame()\n",
    "previous_res = None\n",
    "for i, chunk in enumerate(data): \n",
    "  chunk = chunk[SELECTED_FIELDS].dropna()\n",
    "  chunk[ID_FIELD] = chunk[ID_FIELD].astype('float')  \n",
    "  #\n",
    "  # TRAIN MODEL\n",
    "  #\n",
    "  # This step performs model training and cross-validation. If you do not have API access, e.g. free \n",
    "  # tier users, you will need to replace the training command with your own model.fit() statement \n",
    "  # for model training and cross-validation using local compute resources.  \n",
    "  # \n",
    "  # Note also this version keeps polling the API while the model is training. For longer training runs \n",
    "  # you may want to disable polling and manually check the status of your model (see next cell). \n",
    "  # \n",
    "  client_id = 'test'\n",
    "  algorithm = 'minibatch-kmeans'\n",
    "  N = 5\n",
    "  verbose = True\n",
    "  if previous_res is not None: \n",
    "    res = analyzer.cluster.run(\n",
    "        chunk, client_id=client_id,\n",
    "        idx_var=ID_FIELD, categorical_vars=CATEGORICAL_VARS, numerical_vars=NUMERICAL_VARS, \n",
    "        algorithm=algorithm, n_components=N, \n",
    "        buffer_batch_size=50, verbose=True, poll=True, compressed=True, staging=True, out_of_core=True\n",
    "    )\n",
    "  else: \n",
    "    res = analyzer.cluster.run(\n",
    "        chunk, client_id=client_id,\n",
    "        idx_var=ID_FIELD, categorical_vars=CATEGORICAL_VARS, numerical_vars=NUMERICAL_VARS, \n",
    "        algorithm=algorithm, n_components=N, \n",
    "        buffer_batch_size=200, verbose=True, poll=True, compressed=True, staging=True, out_of_core=True\n",
    "    )\n",
    "  data2 = res['data']\n",
    "  clusters = data2['PC_ID']\n",
    "  total_clusters = pd.concat([total_clusters, clusters], axis=0)\n",
    "  previous_res = res['request_id']\n",
    "  scaled_X_two = pre_process_common(data=chunk, idx_field=ID_FIELD, categorical_fields=CATEGORICAL_VARS)\n",
    "  scaled_X_two = scaled_X_two.drop(columns=ID_FIELD)  \n",
    "  score2 = pd.DataFrame([silhouette_score(scaled_X_two, clusters)])\n",
    "  scores = scores.append(score2)\n",
    "\n",
    "scaled_X = pre_process_common(data=df, idx_field=ID_FIELD, categorical_fields=CATEGORICAL_VARS)\n",
    "scaled_X = scaled_X.drop(columns=ID_FIELD)\n",
    "print(total_clusters)\n",
    "score = silhouette_score(scaled_X, total_clusters)\n",
    "print('model_id: {}'.format(res['request_id']))\n",
    "print('total time: {}'.format(datetime.datetime.now()-t_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10337335076591977"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analyzr3-api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
